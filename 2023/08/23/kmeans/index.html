<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"example.com",root:"/",scheme:"Pisces",version:"7.8.0",exturl:!1,sidebar:{position:"left",width:320,display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!0,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="聚类属于无监督学习，指在没有参照系下对样本集合进行分组，这种分组往往是无标签化的，即分类后无法知道这一类的意义，仅仅是在特征上具有较大相似性。K-means算法是常见的聚类算法，在给定分类组数的情况下算法自动进行分类。"><meta property="og:type" content="article"><meta property="og:title" content="数学建模算法：K-Means聚类算法"><meta property="og:url" content="http://example.com/2023/08/23/kmeans/index.html"><meta property="og:site_name" content="凤凰院魔法使のBlog"><meta property="og:description" content="聚类属于无监督学习，指在没有参照系下对样本集合进行分组，这种分组往往是无标签化的，即分类后无法知道这一类的意义，仅仅是在特征上具有较大相似性。K-means算法是常见的聚类算法，在给定分类组数的情况下算法自动进行分类。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/iris.png"><meta property="og:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/MyKmeans.png"><meta property="og:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/MySSE.png"><meta property="og:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/skl-kmeans.png"><meta property="og:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/SSE.png"><meta property="article:published_time" content="2023-08-23T09:54:02.000Z"><meta property="article:modified_time" content="2023-08-23T10:24:01.000Z"><meta property="article:author" content="Phoenizard"><meta property="article:tag" content="算法"><meta property="article:tag" content="数学建模"><meta property="article:tag" content="机器学习"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/iris.png"><link rel="canonical" href="http://example.com/2023/08/23/kmeans/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>数学建模算法：K-Means聚类算法 | 凤凰院魔法使のBlog</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">凤凰院魔法使のBlog</h1><span class="logo-line-after"><i></i></span></a></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">29</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">25</span></a></li><li class="menu-item menu-item-音游记录"><a href="/rthymgs/" rel="section"><i class="fa fa-database fa-fw"></i>音游记录</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><a href="https://github.com/Phoenizard" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/2023/08/23/kmeans/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Phoenizard"><meta itemprop="description" content="And in that light, I find deliverance"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="凤凰院魔法使のBlog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">数学建模算法：K-Means聚类算法</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-08-23 17:54:02 / 修改时间：18:24:01" itemprop="dateCreated datePublished" datetime="2023-08-23T17:54:02+08:00">2023-08-23</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>5.8k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span><div class="post-description">聚类属于无监督学习，指在没有参照系下对样本集合进行分组，这种分组往往是无标签化的，即分类后无法知道这一类的意义，仅仅是在特征上具有较大相似性。K-means算法是常见的聚类算法，在给定分类组数的情况下算法自动进行分类。</div></div></header><div class="post-body" itemprop="articleBody"><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>聚类属于无监督学习，指在没有参照系下对样本集合进行分组，这种分组往往是无标签化的，即分类后无法知道这一类的意义，仅仅是在特征上具有较大相似性。K-means算法是常见的聚类算法，在给定分类组数的情况下算法自动进行分类。</p><p>K-means算法支持大于2维的特性维度，但不支持过大维度的特性。同时对噪声点较为敏感，需要进行一定的数据处理。在聚类上，关键依据是样本的特征向量在空间中互相的距离。</p><h3 id="几何距离"><a href="#几何距离" class="headerlink" title="几何距离"></a>几何距离</h3><p>距离即为两个样本的间隔，定义样本的特征为：</p><script type="math/tex;mode=display">X = [x_1, x_2, \dots, x_d]^T, d \ refers\  to\  the\  Dimension</script><p>常见距离算法如下：<br>（可参考知乎文章：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/374627115）">https://zhuanlan.zhihu.com/p/374627115）</a></p><ol><li>明氏距离：<script type="math/tex;mode=display">pdist(x, 'minkowski', r) = [\sum_{k=1}^d{|x_{ik} - x_{jk}|^m}]^{\frac{1}{m}}</script></li></ol><ul><li>当m=1时为曼哈顿距离<br>当数据集具有离散和/或二进制属性时，Manhattan似乎工作得很好，因为它考虑了在这些属性的值中实际可以采用的路径。以欧几里得距离为例，它会在两个向量之间形成一条直线，但实际上这是不可能的。</li><li>当m=2时为欧几里得距离<br>尽管欧几里德距离是一种常见的距离度量，但它不是尺度不变的，这意味着计算的距离可能是倾斜的，这取决于特征的单位。通常，在使用这个距离度量之前，需要对数据进行标准化（normalize）。</li></ul><ol><li>切氏距离:<script type="math/tex;mode=display">max(abs(x_i-x_j)) = {max}_{1\leq k \leq d} |x_{ik}-x_{jk}|</script></li><li>马氏距离：<br>马氏距离是欧几里得距离维度，权重归一化后的集合距离，即经过了标准化处理，较为常用：<script type="math/tex;mode=display">pdist(x, 'mahal') = [(x_i-x_j)^T \sum^{-1}(x_i-x_j)]^{\frac{1}{2}}</script></li></ol><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>K-means 有一个著名的解释：牧师—村民模型：</p><blockquote><p>有四个牧师去郊区布道，一开始牧师们随意选了几个布道点，并且把这几个布道点的情况公告给了郊区所有的村民，于是每个村民到离自己家最近的布道点去听课。听课之后，大家觉得距离太远了，于是每个牧师统计了一下自己的课上所有的村民的地址，搬到了所有地址的中心地带，并且在海报上更新了自己的布道点的位置。牧师每一次移动不可能离所有人都更近，有的人发现A牧师移动以后自己还不如去B牧师处听课更近，于是每个村民又去了离自己最近的布道点。就这样，牧师每个礼拜更新自己的位置，村民根据自己的情况选择布道点，最终稳定了下来。我们可以看到该牧师的目的是为了让每个村民到其最近中心点的距离和最小。</p></blockquote><p>从上述故事不难发现K-means分为两步：</p><ol><li>统计k个组的中心对象，并重新按k个中心对象确立k个组</li><li>以中心对象为准则，每个点与k个中心分别计算距离并归近最近中心点的组<br>直到中心对象不再移动，分类完毕。而整个过程的初始是随机给k个点。<br>（虽然这里我们说随机初始值，但是如果初始点与期望分组中心越接近，结果越准确）</li></ol><h4 id="鸢尾花聚类"><a href="#鸢尾花聚类" class="headerlink" title="鸢尾花聚类"></a>鸢尾花聚类</h4><p>鸢尾花数据集是机器学习中相当经典的例子，里面仅仅150个样本，每个样本有4列特征。我们仅仅使用petalWidth, petalLength两组特征数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris     <span class="comment">#从sklearn库中导入鸢尾花数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">Y = iris.target</span><br><span class="line">data = []</span><br><span class="line">petalLength = []</span><br><span class="line">petalWidth = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> iris.data:</span><br><span class="line">    data.append([i[<span class="number">2</span>],i[<span class="number">3</span>]])</span><br><span class="line">    petalLength.append(i[<span class="number">2</span>])</span><br><span class="line">    petalWidth.append(i[<span class="number">3</span>])</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(data[:<span class="number">5</span>]) <span class="comment"># 打印前5个数据</span></span><br><span class="line"><span class="comment"># ================================ #</span></span><br><span class="line">[[<span class="number">1.4</span>, <span class="number">0.2</span>], [<span class="number">1.4</span>, <span class="number">0.2</span>], [<span class="number">1.3</span>, <span class="number">0.2</span>], [<span class="number">1.5</span>, <span class="number">0.2</span>], [<span class="number">1.4</span>, <span class="number">0.2</span>]]</span><br></pre></td></tr></table></figure><p><img src="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/iris.png" style="zoom:67%"></p><p>在K-means算法前，还需要定义两个函数，计算距离与计算组的中心对象，这里我们使用欧式距离：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math, random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eucliDist</span>(<span class="params">A, B</span>):</span><br><span class="line">    <span class="comment"># 多维欧拉距离</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(<span class="string">&#x27;&#123;:.10f&#125;&#x27;</span>.<span class="built_in">format</span>(math.sqrt(<span class="built_in">sum</span>([(a - b)**<span class="number">2</span> <span class="keyword">for</span> (a,b) <span class="keyword">in</span> <span class="built_in">zip</span>(A,B)]))))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">centerPoint</span>(<span class="params">point_set</span>):</span><br><span class="line">    <span class="comment"># 获取点的维度</span></span><br><span class="line">    dim = <span class="built_in">len</span>(point_set[<span class="number">0</span>])</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dim):</span><br><span class="line">        res.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dim):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> point_set:</span><br><span class="line">            res[i] += j[i]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dim):</span><br><span class="line">        res[i] = res[i] / <span class="built_in">len</span>(point_set) <span class="comment"># 每个维度依次求平均，重心求法</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>进入K-means算法部分，按照原理模拟即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myKMeans</span>(<span class="params">n_clusters</span>):</span><br><span class="line">    key_index = random.sample(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(data)), n_clusters)</span><br><span class="line">    <span class="comment"># key_index = [20, 80, 140]</span></span><br><span class="line">    <span class="comment"># 这里并没有选择随机，而是选择了三个直观符合分类分布的三个点为初始值</span></span><br><span class="line">    is_change = <span class="literal">True</span></span><br><span class="line">    key_point = []</span><br><span class="line">    group = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters)]</span><br><span class="line">    cmp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 初始化：以n个关键点分组</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">        group[i].append(data[key_index[i]])</span><br><span class="line">        <span class="comment"># i同时对应group与key</span></span><br><span class="line">        key_point.append(data[key_index[i]])</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 迭代器</span></span><br><span class="line">    <span class="keyword">while</span> is_change:</span><br><span class="line">        <span class="comment"># 遍历所有点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">            <span class="comment"># 与n个目标点比较</span></span><br><span class="line">            tmp_dis = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">                tmp_dis.append(eucliDist(key_point[j], data[i]))</span><br><span class="line">            min_index = np.argmin(np.array(tmp_dis))</span><br><span class="line">            group[min_index].append(data[i])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每组的中心对象</span></span><br><span class="line">        tmp_key_point = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">            new_center = centerPoint(group[i])</span><br><span class="line">            tmp_key_point.append(new_center)</span><br><span class="line">            cmp += <span class="built_in">float</span>(eucliDist(new_center, key_point[i]))</span><br><span class="line">        <span class="comment"># 比较中心点与目标点差异</span></span><br><span class="line">        <span class="keyword">if</span> cmp &lt; <span class="number">0.00002</span>:</span><br><span class="line">            is_change = <span class="literal">False</span></span><br><span class="line">            key_point = tmp_key_point</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            is_change = <span class="literal">True</span></span><br><span class="line">            key_point = tmp_key_point</span><br><span class="line">            cmp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">                group[i][<span class="number">0</span>] = key_point[i]</span><br><span class="line">    predicted = []</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n_clusters):</span><br><span class="line">            <span class="keyword">if</span> d <span class="keyword">in</span> group[j]:</span><br><span class="line">                predicted.append(j)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> predicted, group, key_point</span><br></pre></td></tr></table></figure><p>接收结果并且数据可视化结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">3</span></span><br><span class="line">p, g, k = myKMeans(n)</span><br><span class="line">colors_p = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;red&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;green&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;MyPredicted&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal width&#x27;</span>)</span><br><span class="line">plt.scatter(petalLength, petalWidth, c=colors_p)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/MyKmeans.png" style="zoom:67%"></p><h3 id="选择K值"><a href="#选择K值" class="headerlink" title="选择K值"></a>选择K值</h3><p>在上述例子中，由于我们已知鸢尾花的分类共有3个，所以定义K为3，但是现实中可能我们无法判断出K的取值，这时候我们可以使用手肘法去判断K的合理数值：</p><ol><li><p>定义聚类的误差平方和：</p><script type="math/tex;mode=display">SSE = \sum\limits_{i=1}^{k} \sum\limits_{x\in{c_i}} ||x-\mu_i||^2</script><p>用代码表示实际是遍历每个点与中心点的距离的平方并求和：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square_error</span>(<span class="params">centers, d, p</span>):</span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(d)):</span><br><span class="line">        c = p[i]</span><br><span class="line">        cnt += (eucliDist(centers[c], d[i]) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> cnt</span><br></pre></td></tr></table></figure></li><li><p>返回不同K下的取值:寻找图中的曲折点即可:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sse = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">10</span>):</span><br><span class="line">    p,g,k = myKMeans(i)</span><br><span class="line">    sse.append(square_error(k, data, p))</span><br><span class="line">    </span><br><span class="line">plt.title(<span class="string">&quot;SSE&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SSE&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],sse)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/MySSE.png" style="zoom:50%"></p><h3 id="Sklearn-实现K-means"><a href="#Sklearn-实现K-means" class="headerlink" title="Sklearn 实现K-means"></a>Sklearn 实现K-means</h3><p>Sklearn作为python中的机器学习库已经封装好了K-means算法，使用方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="comment"># K-means 调库</span></span><br><span class="line">estimator = KMeans(n_clusters=<span class="number">3</span>, n_init=<span class="string">&#x27;auto&#x27;</span>).fit(data)  <span class="comment">#聚类</span></span><br><span class="line">label_pred = estimator.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化</span></span><br><span class="line">colors_p = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> label_pred:</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;red&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        colors_p.append(<span class="string">&quot;green&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Predicted&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;petal length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;petal width&#x27;</span>)</span><br><span class="line">plt.scatter(petalLength,petalWidth, c=colors_p)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/skl-kmeans.png" style="zoom:67%"></p><p>同时，由于手写K-means中随机数对结果波动较大，我们可以通过封装的k-means库重新查看一下SSE，引证手肘法选k值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SSE = []  <span class="comment"># 存放每次结果的误差平方和</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">9</span>):</span><br><span class="line">    estimator = KMeans(n_clusters=k)  <span class="comment"># 构造聚类器</span></span><br><span class="line">    estimator.fit(data)</span><br><span class="line">    SSE.append(estimator.inertia_) <span class="comment"># estimator.inertia_获取聚类准则的总和</span></span><br><span class="line">X = <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">9</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;SSE&#x27;</span>)</span><br><span class="line">plt.plot(X,SSE,<span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://phoenizard-picgo.oss-cn-hangzhou.aliyuncs.com/img/SSE.png" style="zoom:67%"></p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E7%AE%97%E6%B3%95/" rel="tag"># 算法</a> <a href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" rel="tag"># 数学建模</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2023/08/22/mm-ahp/" rel="prev" title="数学建模算法：层次分析法"><i class="fa fa-chevron-left"></i> 数学建模算法：层次分析法</a></div><div class="post-nav-item"><a href="/2023/12/14/dijkstra/" rel="next" title="数据结构与算法：最短路径问题（1）">数据结构与算法：最短路径问题（1） <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%A0%E4%BD%95%E8%B7%9D%E7%A6%BB"><span class="nav-number">2.</span> <span class="nav-text">几何距离</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="nav-number">3.</span> <span class="nav-text">算法实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%B8%A2%E5%B0%BE%E8%8A%B1%E8%81%9A%E7%B1%BB"><span class="nav-number">3.1.</span> <span class="nav-text">鸢尾花聚类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%89%E6%8B%A9K%E5%80%BC"><span class="nav-number">4.</span> <span class="nav-text">选择K值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sklearn-%E5%AE%9E%E7%8E%B0K-means"><span class="nav-number">5.</span> <span class="nav-text">Sklearn 实现K-means</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Phoenizard" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">Phoenizard</p><div class="site-description" itemprop="description">And in that light, I find deliverance</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">25</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">29</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/Phoenizard" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Phoenizard" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:jiangxiaoyi2004@163.com" title="E-Mail → mailto:jiangxiaoyi2004@163.com" rel="noopener" target="_blank"><i class="fab fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://profile-pjsekai.kirafan.cn/#/user/196266691860643843" title="PJSKProfile → https:&#x2F;&#x2F;profile-pjsekai.kirafan.cn&#x2F;#&#x2F;user&#x2F;196266691860643843" rel="noopener" target="_blank"><i class="fa-fw"></i>PJSKProfile</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Phoenizard</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">79k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">1:12</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动</div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now=new Date;function createtime(){var n=new Date("08/24/2022 00:00:00");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="本站已安全运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",250)</script></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }</script></body></html>